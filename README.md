# ğŸ¤– Buddy Core  
**Smart Vision and Voice Assistant for Raspberry Pi**  
*An offline AI companion combining object detection, wake-word interaction, and natural speech.*

---

## ğŸŒŸ Overview
**Buddy Core** is an intelligent embedded system that detects objects in real-time, listens for wake words, and interacts through speech â€” all running **offline on a Raspberry Pi**.  
It uses **YOLOv11** for computer vision, **Porcupine** for wake word detection, and **Piper TTS** for natural voice output.

---

## ğŸ§  Features
- ğŸ¯ **Real-time Object Detection** with YOLOv11 (via camera)
- ğŸ”ˆ **Offline Wake Word Detection** (â€œHey Buddyâ€)
- ğŸ—£ **Text-to-Speech (TTS)** using Piper (interruptible)
- âš™ï¸ **Two Operation Modes**
  - **Normal Mode** â†’ reports all detected objects  
  - **Hazard Mode** â†’ reports only hazardous items
- ğŸ’¾ **Automatic Frame Logging** â†’ annotated images saved with timestamp  
  (auto-manages last 100 detection images)
- ğŸ”„ **Modular Design** for easy integration with new AI models or sensors

---

## ğŸ§© System Architecture
```sql
+---------------------------------------------------+
|                     main.py                       |
|---------------------------------------------------|
| â€¢ Coordinates all subsystems                      |
| â€¢ Manages Normal/Hazard modes                     |
| â€¢ Handles wake-word events and voice commands     |
+----------------------------+----------------------+
                             |
                             v
          +------------------+------------------+
          |          WakeWordListener           |
          |-------------------------------------|
          | â€¢ Uses Porcupine offline engine      |
          | â€¢ Detects â€œHey Buddyâ€ and commands   |
          +------------------+------------------+
                             |
                             v
          +------------------+------------------+
          |            ObjectDetector            |
          |-------------------------------------|
          | â€¢ YOLOv11 (ONNX) object detection    |
          | â€¢ Annotates and timestamps frames    |
          | â€¢ Saves last 100 detections          |
          +------------------+------------------+
                             |
                             v
          +------------------+------------------+
          |           AudioController            |
          |-------------------------------------|
          | â€¢ Uses Piper TTS for speech output   |
          | â€¢ Interruptible voice playback       |
          +------------------+------------------+
```
---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/thancsp/buddycore.git
cd buddycore
```
### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 3ï¸âƒ£ Download Required Models
- YOLOv11 ONNX model â†’ place in `models/yolo11`
- Porcupine wake word model â†’ place in `models/porcupine/`
- Piper voice model â†’ place in `models/piper_models`
(See comments in `config.py` for model paths and supported file names.)
## ğŸš€ Usage
Run Buddy Core directly:
```bash
cd buddycore/
source venv/bin/activate
python3 main.py
```
## ğŸ—‚ Folder Structure
```bash
buddycore/
â”œâ”€â”€ main.py
â”œâ”€â”€ audio_controller.py
â”œâ”€â”€ wakeword_listener.py
â”œâ”€â”€ object_detector.py
â”œâ”€â”€ config.py
â”œâ”€â”€ OUTPUT/                # Annotated frames
â”œâ”€â”€ models/                # YOLO + Porcupine
â”œâ”€â”€ voices/                # Piper TTS models
â””â”€â”€ test/                  # Optional test scripts
```
## ğŸ“¸ Output
Each detection is saved to the `OUTPUT/` folder as:
```bash
[DETECTED]YYYY-MM-DD-HH-MM-SS.jpg
```
- Timestamp overlay at top-left
- Bounding boxes for detected objects
- Folder automatically pruned to keep the latest 100 images
## ğŸ§ª Testing
To run the test sequence:
```bash
python3 test/test_launcher.py
```
Follow the on screen instructions
## ğŸ” License
MIT License Â© 2025 Than Chaiboriphan (on behalf of Saint Paul Convent School, Thailand)
## ğŸ™Œ Acknowledgments
- [Ultralytics YOLOv11](https://github.com/ultralytics/ultralytics)
- [Picovoice Porcupine](https://github.com/Picovoice/porcupine)
- [Piper TTS](https://github.com/OHF-Voice/piper1-gpl)
- [Raspberry Pi Foundation](https://www.raspberrypi.org)
---
